\section{Control}\label{sec:control}

%\subsection{Attitude Control}

%Taking into account the dynamics of the system, a simplified Proportional controller for the corresponding attitude loop, and a Proportional-Integral controller for the position loop is proposed. Effectively, this transforms the proposed two stage cascade controller structure into a single PI-Derivative position controller. The proposed PI-D controller equation~(\ref{eq:ControlLaw}) implies that the control difference $\vec{e}$ is taken through the proportional and integration channels, while the derivative channel is connected directly to speed measurements of the quadrotor $\vec{v}_0$. Equations are written in vector form because they are applied to $x, y, z$ positions in 3D space.

%\begin{equation}\label{eq:ControlLaw}
%	\centering
%	\begin{aligned}
%	\vec{u}=K_P \vec{e} + K_I\int {\vec{e}}+ K_D \vec{v}_0 
%	\end{aligned}
%\end{equation}

%\begin{figure}[t]
%	\centering
%	\includegraphics[width=0.5\textwidth]{./pictures/simulation}
%	\caption{MM-UAV Control Structure}
%	\label{fig:MMUAVControlStructure}
%\end{figure}

%$K_P$, $K_I$, and $K_D$ are the PI-D control gains. Error vector $\vec{e}$ is the difference between the $x, y, z$ position data and the actual setpoint reference values, and $\vec{v}$ is the speed measurement. Due to the fact that the derivation channel (i.e. aircraft speed) is error sensitive, leading the control difference directly through can cause serious problems and possibly damage the aircraft. On the other hand, position data is much more reliable and can be used directly in the control loop. PI-D position control is implemented as a Python class, running at a 20 Hz refresh rate.

%\subsection{Feature Detection through Ellipsoid Tracking}

%Feature detection has been extensively used by rotorcraft to achieve hover for surveillance and localization \cite{Bourquardez2009}, \cite{Romero2006}. 

%\cite{Ahmadzadeh2013}

%\subsection{Visual Servoing and Position Control}

%\begin{figure}[b]
%	\centering
%	\includegraphics[width=0.5\textwidth]{./pictures/MMUAS_peg_in_hole}
%	\caption{Camera Reference Frame (camera in an exploded view for clarity)}
%	\label{fig:camera}
%\end{figure}

%Image Based Visual Servoing (IBVS) has been extensively used by rotorcraft to achieve hover for surveillance and localization \cite{Bourquardez2009}, \cite{Romero2006}. An \emph{eye-in-hand} system is used where the camera is attached to the end-effector. The camera frame relative to the end-effector frame is known \emph{a priori} as shown in Fig.~\ref{fig:camera}. The transformation between the image feature velocities, $\dot{s}$, and the joint velocities, $\dot{q}$, must be determined where:

%\begin{equation}
%	s=J(x,y,Z,q) \dot{q}
%\end{equation}
%The center location of the camera frame $(u,\;v)$ is projected into Cartesian coordinates where $C = (X_C, \; Y_C, \; Z_C)$ of the center of the hole. Using the center location, $d$ is calculated to determine the distance of the target hole to the camera.

%The control inputs consist of $x, \; y, \; z$ position and yaw $\psi$ orientation of the quadrotor, yaw joint $q_1$, pitch joint $q_2$, and roll joint $q_3$ of the end-effector. The total controllable degrees of freedom for the aircraft-arm system is seven. As the wrist is spherical with intersecting axes of rotation, the inverse kinematic calculations are greatly simplified to determine joint angles for a desired pose and orientation. The arm can be described as a series of transforms:

%\begin{equation}
%	T = A_{0T} = A_{01}A_{12}(q_1)A_{23}(q_2)A_{3T}(q_3)
%\end{equation}
%where $A_{01}$ is the fixed transform from the center of a quadrotor and $A_{3T}$ is the transform from the last joint of the arm ($q_3$) to the tool tip. $A_{AB}$ is the transform from joint A to joint B and is driven by the angle of joint $A(q_A)$. With the vehicle at a specified position and yaw orientation, the next step is to solve for the spherical wrist joints ($q_1, q_2, q_3$) using the method described in \cite{Tsai1985}. The first step in this process is to identify the transform that represents the combined joint rotations from the wrist to the target $(A_{3T})$ where:
%\begin{equation}
%	A_{3T} = A^{-1}_{3T}
%\end{equation}
%Next, $q_1, q_2$, and $q_3$ are calculated directly from $A_{3T}$ where:

%\begin{subequations}
%\begin{align}
%q_1 = atan2(A_{3T}[2,3],A_{3T}[1,3]) \\
%q_2 = atan2(\sqrt{(A_{3T}[1,3]^2+A_{3T}[2,3]^2},A_{3T}[3,3]) \\
%q_3 = atan2(A_{3T}[3,2],-A_{3T}[3,1])
%\end{align}
%\end{subequations}
%to generate the closed form solution for the joint angles.

%\subsection{Force Feedback}

An impedance control strategy is proposed to control the dynamic interaction between the manipulators and their environment. Impedance control enables contact between the manipulator and its environment while maintaining stability during the transition from free motion to interaction \cite{Hogan1984}. In a simplified manner, the manipulators can be seen as a mass-spring-damper system behaving like an impedance towards the environment. The controller applies prescribed interaction forces at the end effector which are calculated as:

\begin{equation}
 	F_{int}=K[X_0-X]
	\label{eq:eq7}
\end{equation}
where $F_{int}$ is the desired interaction force to be applied at the end effector, and $X_0-X$ is the position error and $K$ is a stiffness gain to map between position error and interaction force. $K$ can be thought of as a spring constant while $X_0-X$ can be thought of as the spring's compression. (\ref{eq:eq7}) can be rearranged to solve for a pseudo-goal position to command the end effector to, using the position controller that will impart the desired amount of force. To achieve this, we need to calculate the torques necessary to command each joint where:

\begin{equation}
	T_{act}=J^{\#T}F_{int}
	\label{eq:eq8}
\end{equation}
Combining \ref{eq:eq7} and \ref{eq:eq8}, we have:

\begin{equation}
	T_{act}=J^{\#T}K[X_0-X]
	\label{eq:eq9}
\end{equation}
to represent overall commanded joint torques.